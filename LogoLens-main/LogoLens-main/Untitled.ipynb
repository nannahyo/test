{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e113cde8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'object_detection'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_4900\\3846117262.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnamedtuple\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdataset_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'object_detection'"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "from object_detection.utils import dataset_util\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import io\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-l', '--labelmap_file', help='The path of labelmap file.')\n",
    "parser.add_argument('-o', '--output_path', help='The output path of record.')\n",
    "parser.add_argument('-i', '--image_dir', help='The images directory.')\n",
    "parser.add_argument('-csv', '--csv_input', help='The csv input path.')\n",
    "\n",
    "\n",
    "def split(df, group):\n",
    "    data = namedtuple('data', ['filename', 'object'])\n",
    "    gb = df.groupby(group)\n",
    "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
    "\n",
    "\n",
    "def init_names(labelmap):\n",
    "    items = labelmap.split('item')[1:]\n",
    "    items_dict = {}\n",
    "    for item in items:\n",
    "        name = str(item.split('name')[1].split('\"')[1])\n",
    "        name_id = int(item.split('name')[1].split('id')[1].split(\": \")[1].split('}')[0])\n",
    "\n",
    "        items_dict[name] = name_id\n",
    "    return items_dict\n",
    "\n",
    "\n",
    "class TFRecord:\n",
    "    def __init__(self, labelmap_file):\n",
    "        f = open(labelmap_file, \"r\")\n",
    "        labelmap = f.read()\n",
    "        self.class_names = init_names(labelmap)\n",
    "\n",
    "    def class_text_to_int(self, row_label):\n",
    "        if self.class_names[row_label] is not None:\n",
    "            return self.class_names[row_label]\n",
    "\n",
    "    def create_tf(self, group, path):\n",
    "        with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
    "            encoded_jpg = fid.read()\n",
    "        encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "        image = Image.open(encoded_jpg_io)\n",
    "        width, height = image.size\n",
    "\n",
    "        filename = group.filename.encode('utf8')\n",
    "        image_format = b'jpg'\n",
    "        xmins = []\n",
    "        xmaxs = []\n",
    "        ymins = []\n",
    "        ymaxs = []\n",
    "        classes_text = []\n",
    "        classes = []\n",
    "\n",
    "        for index, row in group.object.iterrows():\n",
    "            xmins.append(row['xmin'] / width)\n",
    "            xmaxs.append(row['xmax'] / width)\n",
    "            ymins.append(row['ymin'] / height)\n",
    "            ymaxs.append(row['ymax'] / height)\n",
    "            classes_text.append(row['class'].encode('utf8'))\n",
    "            classes.append(self.class_text_to_int(row['class']))\n",
    "\n",
    "        tf_sample = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'image/height': dataset_util.int64_feature(height),\n",
    "            'image/width': dataset_util.int64_feature(width),\n",
    "            'image/filename': dataset_util.bytes_feature(filename),\n",
    "            'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "            'image/format': dataset_util.bytes_feature(image_format),\n",
    "            'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "            'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "            'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "            'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "            'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "            'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "        }))\n",
    "        return tf_sample\n",
    "\n",
    "    def generate(self, output_path, image_dir, csv_input):\n",
    "        writer = tf.io.TFRecordWriter(output_path)\n",
    "        path = os.path.join(image_dir)\n",
    "        data = pd.read_csv(csv_input)\n",
    "        grouped = (split(data, 'filename'))\n",
    "        random.shuffle(grouped)\n",
    "\n",
    "        for group in grouped:\n",
    "            tf_sample = self.create_tf(group, path)\n",
    "            writer.write(tf_sample.SerializeToString())\n",
    "\n",
    "        print('Generated tf record.')\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = parser.parse_args()\n",
    "    tf_record = TFRecord(args.labelmap_file)\n",
    "    tf_record.generate(args.output_path, args.image_dir, args.csv_input)\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcdbed3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
